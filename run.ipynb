{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "\n",
    "from PIL import Image\n",
    "from utils.helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from src.unet_keras import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 10 images\n",
      "satImage_052.png\n",
      "Loading 10 images\n",
      "satImage_052.png\n"
     ]
    }
   ],
   "source": [
    "# Loaded a set of images\n",
    "root_dir = \"data/training/\"\n",
    "\n",
    "image_dir = root_dir + \"images/\"\n",
    "files = os.listdir(image_dir)\n",
    "n = min(10, len(files)) # Load maximum 20 images\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "imgs = [load_image(image_dir + files[i]) for i in range(n)]\n",
    "print(files[0])\n",
    "\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "gt_imgs = [load_image(gt_dir + files[i]) for i in range(n)]\n",
    "print(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(imgs)\n",
    "y_train = np.expand_dims(np.asarray(gt_imgs), axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 400, 400, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 400, 400, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 400\n",
    "NUM_CHANNELS = 3\n",
    "NUM_FILTER = 16\n",
    "FILTER_SIZE = 3\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/olivier/anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = unet_model(IMG_SIZE, NUM_CHANNELS, NUM_FILTER, FILTER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5 samples, validate on 3 samples\n",
      "WARNING:tensorflow:From /Users/olivier/anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 21s 4s/sample - loss: 4.5745 - acc: 0.2992 - val_loss: 2.2542 - val_acc: 0.0946\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 7s 1s/sample - loss: 4.3526 - acc: 0.3128 - val_loss: 2.2290 - val_acc: 0.1686\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 7s 1s/sample - loss: 4.1982 - acc: 0.3173 - val_loss: 2.2024 - val_acc: 0.2178\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 7s 1s/sample - loss: 4.0630 - acc: 0.3204 - val_loss: 2.2058 - val_acc: 0.2325\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 7s 1s/sample - loss: 3.9373 - acc: 0.3322 - val_loss: 2.2717 - val_acc: 0.2387\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 7s 1s/sample - loss: 3.8105 - acc: 0.3492 - val_loss: 2.4179 - val_acc: 0.2372\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 8s 2s/sample - loss: 3.6767 - acc: 0.3710 - val_loss: 2.6372 - val_acc: 0.2351\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 7s 1s/sample - loss: 3.5330 - acc: 0.3960 - val_loss: 2.9125 - val_acc: 0.2376\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 7s 1s/sample - loss: 3.3777 - acc: 0.4253 - val_loss: 3.3405 - val_acc: 0.2345\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 8s 2s/sample - loss: 3.2133 - acc: 0.4611 - val_loss: 3.9413 - val_acc: 0.2183\n",
      "\n",
      "history dict: {'loss': [4.574549674987793, 4.352640628814697, 4.198201656341553, 4.062991142272949, 3.937345027923584, 3.8104615211486816, 3.6767079830169678, 3.5329957008361816, 3.377697706222534, 3.2133491039276123], 'acc': [0.29923874, 0.312755, 0.31728876, 0.32044, 0.33215374, 0.34917, 0.37102124, 0.39601624, 0.42529374, 0.46114376], 'val_loss': [2.2541563510894775, 2.2289695739746094, 2.202427864074707, 2.2058496475219727, 2.271721839904785, 2.417898178100586, 2.6372108459472656, 2.9125008583068848, 3.340498924255371, 3.9413208961486816], 'val_acc': [0.09457708, 0.16856042, 0.21777292, 0.23251042, 0.23871459, 0.23723958, 0.23510833, 0.23755416, 0.23448125, 0.21828125]}\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, x_train[:5], y_train[:5], x_train[5:8], y_train[5:8], BATCH_SIZE, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Evaluate on test data\n",
      "2/2 [==============================] - 1s 460ms/sample - loss: 2.7249 - acc: 0.2188\n",
      "test loss, test acc: [2.7249317169189453, 0.21883126]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print('\\n# Evaluate on test data')\n",
    "results = model.evaluate(x_train[8:], y_train[8:])\n",
    "print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Generate predictions for 3 samples\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print('\\n# Generate predictions for 3 samples')\n",
    "predictions = model.predict(x_train[:3])\n",
    "print('predictions shape:', predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
